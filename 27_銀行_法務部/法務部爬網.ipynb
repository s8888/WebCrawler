{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "Project Name: bankingGov project\n",
    "Crawl Cycle: Daily\n",
    "Main Website: https://www.moj.gov.tw/lp-22-001-1-20.html\n",
    "author      : 林德昌\n",
    "date        : 2018/10/16\n",
    "description : 抓取法務部每天發布的最新消息\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import header\n",
    "import logging\n",
    "import re\n",
    "import datetime\n",
    "import traceback # 印log\n",
    "import os\n",
    "import ssl\n",
    "TempPath = \"./Temp\"  # browser file\n",
    "FinalPath = \"./Result\" # project file\n",
    "lastResultPath = \"./CrawlList/lastResult.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downloadFile(finalPath, title, fileUrls, fileNames): # for download pdf or doc\n",
    "    target = finalPath + '/' + title[:30].strip()\n",
    "    # 若目錄不存在，建立目錄\n",
    "    if not os.path.isdir(target):\n",
    "        os.makedirs(target)\n",
    "    for file_url, fileName in zip(fileUrls, fileNames):\n",
    "        try:\n",
    "            logging.info(fileName.strip())\n",
    "            response = requests.get(file_url, stream=\"TRUE\")\n",
    "            downloadFile = target + '/' + fileName.strip() # 放置資料夾路徑 + 檔名\n",
    "            logging.info(downloadFile)\n",
    "            with open(downloadFile,'wb') as file:\n",
    "                for data in response.iter_content():\n",
    "                    file.write(data)\n",
    "        except:\n",
    "            logging.error(\"爬取檔案失敗\")\n",
    "            logging.error(\"失敗連結：\" + file_url)\n",
    "            logging.error('title:' + title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataProcess_Detail(soup, row):\n",
    "    urlmoj = 'https://law.moj.gov.tw' # linkto 全國法規資料庫\n",
    "    urlGazette = 'http://gazette.nat.gov.tw' # linkto 行政院公報資訊網\n",
    "    fileUrlRoot_moj = 'https://law.moj.gov.tw/news/'\n",
    "    urlNTPC = 'http://web.law.ntpc.gov.tw' # linkto 新北市政府網站\n",
    "    title = row['標題']\n",
    "    link = row['內文連結']\n",
    "    result = dict()\n",
    "    if link.find(urlmoj) >= 0:\n",
    "        rawcontent = [e.text for e in soup.select('.text-pre')]\n",
    "        content = rawcontent[0] if bool(rawcontent) else ''\n",
    "        fileNames = [e.text for e in soup.select('#litFile a')]\n",
    "        fileUrls = [urlmoj + '/' + e.get('href') for e in soup.select('#Content a')]\n",
    "        serno = ''\n",
    "        issue_date = [e.text for e in soup.select('td')][0]\n",
    "    elif link.find(urlGazette) >= 0:\n",
    "        fileUrls = [urlGazette + e.get('src') for e in soup.select('.embed-responsive-item')]\n",
    "        fileNames = [title + '.pdf'for i in range(len(fileUrls))]\n",
    "        content = ''\n",
    "        serno = soup.select('div.Item section.Block p span')[2].text\n",
    "        issue_date = soup.select('div.Item section.Block p span')[1].text\n",
    "    elif link.find('NewsContent.aspx') >= 0: # 其他地方政府網站內文\n",
    "        NotFoundmsg = [e.text for e in soup.select('.text-danger')]  \n",
    "        if NotFoundmsg != []:  # 若查詢結果為錯誤訊息，則回傳空的dict\n",
    "            return result\n",
    "        pattern = re.compile(r'http(\\:|\\w|\\.|\\-|\\/)+\\/')\n",
    "        m = pattern.match(link)\n",
    "        content = [e.text.strip() for e in soup.select('.ClearCss')]\n",
    "        content = '' if not bool(content) else content[0]\n",
    "        fileUrls = [m.group(0) + e.get('href') for e in soup.select('#ctl00_cp_content_ulAnnFiles02 a')]\n",
    "        fileNames = [e.text for e in soup.select('#ctl00_cp_content_ulAnnFiles02 a')]\n",
    "        serno = [e.text.strip() for e in soup.select('#ctl00_cp_content_trODWord td')][0]\n",
    "        issue_date = [e.text.strip() for e in soup.select('#ctl00_cp_content_trAnnDate td')]\n",
    "    elif link.find(urlNTPC) >= 0:  \n",
    "        fileUrls = [e.get('href').replace('./', 'http://web.law.ntpc.gov.tw/fn/') for e in soup.select('#Law-Content a')][1:]\n",
    "        fileNames = [e.text for e in soup.select('#Law-Content a')][1:]\n",
    "        content = ''\n",
    "        serno = ''\n",
    "        issue_date = [e.text.strip() for e in soup.select('td b')][0]\n",
    "        if fileNames == []:\n",
    "            contents = [e.text for e in soup.select('.worddisaplay')][0]\n",
    "    else:\n",
    "        logging.info('出現新的連結網站，需要新增爬蟲程式')\n",
    "    result['fileUrls'] = fileUrls\n",
    "    result['fileNames'] = fileNames \n",
    "    result['content'] = content\n",
    "    result['serno'] = serno\n",
    "    result['issue_date'] = issue_date\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsingDetail(df, finalPath): \n",
    "    df2 = pd.DataFrame(columns = [\"標題\", \"全文內容\", \"附件\", \"發文字號\", \"發文日期\", \"相關法條\"])\n",
    "    for index, row in df.iterrows():\n",
    "        try:\n",
    "            title = row['標題']\n",
    "            link = row['內文連結']\n",
    "            logging.info(title)\n",
    "            soup = request2soup(link)\n",
    "            result = dataProcess_Detail(soup, row)\n",
    "            fileNames = result['fileNames'] \n",
    "            if len(fileNames) != 0:\n",
    "                downloadFile(finalPath, title, result['fileUrls'], fileNames)\n",
    "            d = {'標題': title, '全文內容': result['content'], '附件':','.join(fileNames), '發文字號':result['serno'], \n",
    "                 '發文日期':result['issue_date'], '相關法條':''}\n",
    "            df2= df2.append(d, ignore_index=True)\n",
    "        except:\n",
    "            logging.error(\"爬取內文失敗\\n\")\n",
    "            logging.error(\"失敗連結：\" + link+ '\\n')\n",
    "            traceback.print_exc()\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outputCsv(df, fileName, path):\n",
    "    # 若目錄不存在，建立目錄\n",
    "    if not os.path.isdir(path):\n",
    "        os.mkdir(path)\n",
    "    df.to_csv(path + \"/\" + fileName + \".csv\", index = False, encoding = \"utf_8_sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compareTo(strDate, endDate):\n",
    "    strDate = re.sub(r'(/|-|\\.)', '-', strDate)\n",
    "    endDate = re.sub(r'(/|-|\\.)', '-', endDate)\n",
    "    if int(re.split('-', strDate)[0]) < 1911:\n",
    "        strDate = datetime.datetime.strptime(str(int(re.sub('-', '', strDate)) + 19110000), \"%Y%m%d\").strftime(\"%Y-%m-%d\")\n",
    "    if int(re.split('-', endDate)[0]) < 1911:\n",
    "        endDate = datetime.datetime.strptime(str(int(re.sub('-', '', endDate)) + 19110000), \"%Y%m%d\").strftime(\"%Y-%m-%d\")\n",
    "    try:\n",
    "        strDate = datetime.datetime.strptime(strDate, \"%Y-%m-%d\")\n",
    "        endDate = datetime.datetime.strptime(endDate, \"%Y-%m-%d\")\n",
    "\n",
    "    except:\n",
    "        logging.error('compareTo(strDate, endDate):')\n",
    "        logging.error(\"日期格式錯誤：strDate = %s, endDate = %s\" %(strDate, endDate))\n",
    "        traceback.print_exc()\n",
    "        return\n",
    "    if strDate < endDate:\n",
    "        return 1\n",
    "    elif strDate == endDate:\n",
    "        return 0\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataProcess_Title(soup, strDate):\n",
    "    result = dict()\n",
    "    titles_result = []\n",
    "    dates = []\n",
    "    links = []\n",
    "    nowPage = 1\n",
    "    end = False\n",
    "    while True:\n",
    "        try:\n",
    "            if nowPage == 2: # TODO\n",
    "                break\n",
    "            if nowPage > 1:\n",
    "                url = 'https://www.moj.gov.tw/lp-22-001-' + str(nowPage) +'-20.html'\n",
    "                soup = request2soup(url)\n",
    "            titles = [str(e.get('title')) for e in soup.select('.list a')]\n",
    "            if titles == []:\n",
    "                break\n",
    "#             for index in range(len(titles)):\n",
    "            for index in range(15): #TODO\n",
    "                try:\n",
    "                    title = titles[index]\n",
    "                    date = soup.select('td[data-title=\"張貼日\"]')[index].text.strip()\n",
    "                    if compareTo(date, strDate) > 0:\n",
    "                        end = True\n",
    "                        break\n",
    "                    link = soup.select('.list a')[index].get('href')\n",
    "                    titles_result.append(title)\n",
    "                    dates.append(date)\n",
    "                    links.append(link)\n",
    "                except:\n",
    "                    logging.error(\"爬取第 %s 頁第 %s 筆主旨發生錯誤\" %(nowPage, index + 1))\n",
    "            if end == True:\n",
    "                break\n",
    "            nowPage += 1\n",
    "        except:\n",
    "            logging.error(\"爬取第 %s 頁主旨發生錯誤\" %(nowPage))\n",
    "            traceback.print_exc()\n",
    "        \n",
    "    result['titles_result'] = titles_result\n",
    "    result['dates'] = dates\n",
    "    result['links'] = links\n",
    "    result['nowPage'] = nowPage\n",
    "    result['index'] = index + 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsingTitle(soup, checkRange):\n",
    "    \n",
    "    try:\n",
    "        # 取得上次爬網結果\n",
    "        if os.path.isfile(lastResultPath):\n",
    "            lastResult = pd.read_csv(lastResultPath)\n",
    "        else:\n",
    "            lastResult = pd.DataFrame()\n",
    "            \n",
    "        endDate = datetime.date.today()\n",
    "        strDate = (endDate - datetime.timedelta(days = checkRange)).isoformat()\n",
    "        df = pd.DataFrame(columns=['爬網日期','發文日期','標題','內文連結'])\n",
    "        \n",
    "         # 資料處理\n",
    "        result = dataProcess_Title(soup, strDate)   \n",
    "        \n",
    "        d = {'爬網日期':endDate,'發文日期': result['dates'], '標題': result['titles_result'], '內文連結': result['links']}\n",
    "        df = df.append(pd.DataFrame(data=d))\n",
    "        # 若與上次發文日期和標題相同，則跳至下一筆\n",
    "        if not lastResult.empty:\n",
    "            for index, row in df.iterrows():\n",
    "                if (row['發文日期'] in list(lastResult['發文日期'])) and (row['標題'] in list(lastResult['標題'])):\n",
    "                    df.drop(index, inplace = True)\n",
    "\n",
    "        if len(df) == 0:\n",
    "            logging.critical(\"%s 至 %s 間無資料更新\" %(strDate, endDate))\n",
    "        else:\n",
    "            df.index = [i for i in range(df.shape[0])] # reset\n",
    "            outputCsv(df, \"lastResult\", \"./CrawlList\")\n",
    "\n",
    "    except:\n",
    "        logging.error(\"爬取主旨列表失敗\")\n",
    "        traceback.print_exc()\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request2soup(url):\n",
    "    res = requests.get(url)\n",
    "    res.encoding = 'utf-8'\n",
    "    soup = BeautifulSoup(res.text,'html.parser',from_encoding='utf-8')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(url, checkRange = 5):\n",
    "    \n",
    "    logging.critical(\"\\n\")\n",
    "    logging.critical(\"爬網開始......\")\n",
    "    logging.critical(\"目標網址：\" + url)\n",
    "    \n",
    "    strTime = datetime.datetime.now()\n",
    "    logging.critical(\"開始時間：\" + strTime.strftime(\"%Y/%m/%d %H:%M:%S\"))\n",
    "    \n",
    "    try:\n",
    "        soup = request2soup(url)\n",
    "        df_1 = parsingTitle(soup, checkRange)\n",
    "        if len(df_1) == 0:\n",
    "            return\n",
    "        outputCsv(df_1, \"第一層結果\", FinalPath)\n",
    "\n",
    "        df_2 = parsingDetail(df_1, FinalPath)\n",
    "        outputCsv(df_2, \"第二層結果\", FinalPath)\n",
    "    except:\n",
    "        logging.error(\"執行爬網作業失敗\")\n",
    "        traceback.print_exc()\n",
    "    \n",
    "    endTime = datetime.datetime.now()\n",
    "    logging.critical(\"結束時間：\" + endTime.strftime(\"%Y/%m/%d %H:%M:%S\"))\n",
    "    logging.critical(\"執行時間：\" + str((endTime - strTime).seconds) + \" 秒\")\n",
    "    logging.critical(\"輸出筆數：\" + str(len(df_1)) + \" 筆\")\n",
    "    logging.critical(\"爬網結束......\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-10 17:28:15,916 - <ipython-input-90-6ad1ddc58d47>[line:3] - CRITICAL: \n",
      "\n",
      "2019-01-10 17:28:15,920 - <ipython-input-90-6ad1ddc58d47>[line:4] - CRITICAL: 爬網開始......\n",
      "2019-01-10 17:28:15,923 - <ipython-input-90-6ad1ddc58d47>[line:5] - CRITICAL: 目標網址：https://www.moj.gov.tw/lp-22-001-1-20.html\n",
      "2019-01-10 17:28:15,924 - <ipython-input-90-6ad1ddc58d47>[line:8] - CRITICAL: 開始時間：2019/01/10 17:28:15\n",
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:179: UserWarning: You provided Unicode markup but also provided a value for from_encoding. Your from_encoding will be ignored.\n",
      "  warnings.warn(\"You provided Unicode markup but also provided a value for from_encoding. Your from_encoding will be ignored.\")\n",
      "2019-01-10 17:28:16,693 - <ipython-input-84-04431583ed67>[line:7] - INFO: 教育部令：修正「教育部補助師資培育之大學辦理學術研討會作業要點」，自即日生效\n",
      "2019-01-10 17:28:19,061 - <ipython-input-82-1f7a555caa04>[line:8] - INFO: 教育部令：修正「教育部補助師資培育之大學辦理學術研討會作業要點」，自即日生效.pdf\n",
      "2019-01-10 17:28:19,211 - <ipython-input-82-1f7a555caa04>[line:11] - INFO: ./Result/教育部令：修正「教育部補助師資培育之大學辦理學術研討會作業要/教育部令：修正「教育部補助師資培育之大學辦理學術研討會作業要點」，自即日生效.pdf\n",
      "2019-01-10 17:28:26,468 - <ipython-input-84-04431583ed67>[line:7] - INFO: 內政部令：修正「臺灣警察專科學校甄試具特殊專長人員入學辦法」\n",
      "2019-01-10 17:28:28,763 - <ipython-input-82-1f7a555caa04>[line:8] - INFO: 內政部令：修正「臺灣警察專科學校甄試具特殊專長人員入學辦法」.pdf\n",
      "2019-01-10 17:28:28,889 - <ipython-input-82-1f7a555caa04>[line:11] - INFO: ./Result/內政部令：修正「臺灣警察專科學校甄試具特殊專長人員入學辦法」/內政部令：修正「臺灣警察專科學校甄試具特殊專長人員入學辦法」.pdf\n",
      "2019-01-10 17:28:30,276 - <ipython-input-84-04431583ed67>[line:7] - INFO: 金融監督管理委員會令：修正「信用合作社非社員交易限額標準」第2條、第4條條文\n",
      "2019-01-10 17:28:32,824 - <ipython-input-82-1f7a555caa04>[line:8] - INFO: 金融監督管理委員會令：修正「信用合作社非社員交易限額標準」第2條、第4條條文.pdf\n",
      "2019-01-10 17:28:32,963 - <ipython-input-82-1f7a555caa04>[line:11] - INFO: ./Result/金融監督管理委員會令：修正「信用合作社非社員交易限額標準」第/金融監督管理委員會令：修正「信用合作社非社員交易限額標準」第2條、第4條條文.pdf\n",
      "2019-01-10 17:28:34,637 - <ipython-input-84-04431583ed67>[line:7] - INFO: 交通部令：修正「水域遊憩活動管理辦法」第9條、第10條條文、「發展觀光條例裁罰標準」第12條附表8\n",
      "2019-01-10 17:28:37,990 - <ipython-input-82-1f7a555caa04>[line:8] - INFO: 交通部令：修正「水域遊憩活動管理辦法」第9條、第10條條文、「發展觀光條例裁罰標準」第12條附表8.pdf\n",
      "2019-01-10 17:28:38,134 - <ipython-input-82-1f7a555caa04>[line:11] - INFO: ./Result/交通部令：修正「水域遊憩活動管理辦法」第9條、第10條條文、/交通部令：修正「水域遊憩活動管理辦法」第9條、第10條條文、「發展觀光條例裁罰標準」第12條附表8.pdf\n",
      "2019-01-10 17:28:44,692 - <ipython-input-84-04431583ed67>[line:7] - INFO: 金融監督管理委員會令：廢止財政部90年12月11日台財融（三）字第0903000415號令，自即日生效\n",
      "2019-01-10 17:28:46,592 - <ipython-input-82-1f7a555caa04>[line:8] - INFO: 金融監督管理委員會令：廢止財政部90年12月11日台財融（三）字第0903000415號令，自即日生效.pdf\n",
      "2019-01-10 17:28:46,753 - <ipython-input-82-1f7a555caa04>[line:11] - INFO: ./Result/金融監督管理委員會令：廢止財政部90年12月11日台財融（三/金融監督管理委員會令：廢止財政部90年12月11日台財融（三）字第0903000415號令，自即日生效.pdf\n",
      "2019-01-10 17:28:47,456 - <ipython-input-84-04431583ed67>[line:7] - INFO: 修正「雲林縣一般事業廢棄物代清除處理收費標準」。\n",
      "2019-01-10 17:28:47,609 - <ipython-input-82-1f7a555caa04>[line:8] - INFO: 雲林縣一般事業廢棄物代清除處理收費標準.pdf\n",
      "2019-01-10 17:28:47,675 - <ipython-input-82-1f7a555caa04>[line:11] - INFO: ./Result/修正「雲林縣一般事業廢棄物代清除處理收費標準」。/雲林縣一般事業廢棄物代清除處理收費標準.pdf\n",
      "2019-01-10 17:28:48,217 - <ipython-input-84-04431583ed67>[line:7] - INFO: 教育部令：修正「教育部補助大專校院延攬國際頂尖人才作業要點」，自即日生效\n",
      "2019-01-10 17:28:50,608 - <ipython-input-82-1f7a555caa04>[line:8] - INFO: 教育部令：修正「教育部補助大專校院延攬國際頂尖人才作業要點」，自即日生效.pdf\n",
      "2019-01-10 17:28:50,731 - <ipython-input-82-1f7a555caa04>[line:11] - INFO: ./Result/教育部令：修正「教育部補助大專校院延攬國際頂尖人才作業要點」/教育部令：修正「教育部補助大專校院延攬國際頂尖人才作業要點」，自即日生效.pdf\n",
      "2019-01-10 17:28:53,542 - <ipython-input-84-04431583ed67>[line:7] - INFO: 勞動部令：核釋「就業服務法」第47條規定雇主在國內辦理招募本國人從事第46條第1項第8款至第11款工作之合理勞動條件薪資基準，自即日生效\n",
      "2019-01-10 17:28:55,853 - <ipython-input-82-1f7a555caa04>[line:8] - INFO: 勞動部令：核釋「就業服務法」第47條規定雇主在國內辦理招募本國人從事第46條第1項第8款至第11款工作之合理勞動條件薪資基準，自即日生效.pdf\n",
      "2019-01-10 17:28:56,018 - <ipython-input-82-1f7a555caa04>[line:11] - INFO: ./Result/勞動部令：核釋「就業服務法」第47條規定雇主在國內辦理招募本/勞動部令：核釋「就業服務法」第47條規定雇主在國內辦理招募本國人從事第46條第1項第8款至第11款工作之合理勞動條件薪資基準，自即日生效.pdf\n",
      "2019-01-10 17:28:57,310 - <ipython-input-84-04431583ed67>[line:7] - INFO: 修正「雲林縣一般事業廢棄物代清除處理收費標準」\n",
      "2019-01-10 17:28:57,420 - <ipython-input-84-04431583ed67>[line:17] - ERROR: 爬取內文失敗\n",
      "\n",
      "2019-01-10 17:28:57,423 - <ipython-input-84-04431583ed67>[line:18] - ERROR: 失敗連結：http://law.yunlin.gov.tw/NewsContent.aspx?id=11391\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-84-04431583ed67>\", line 10, in parsingDetail\n",
      "    fileNames = result['fileNames']\n",
      "KeyError: 'fileNames'\n",
      "2019-01-10 17:28:57,424 - <ipython-input-84-04431583ed67>[line:7] - INFO: 經濟部公告：修正「許可業者自行檢定之法定度量衡器種類及範圍」，自即日生效\n",
      "2019-01-10 17:28:59,700 - <ipython-input-82-1f7a555caa04>[line:8] - INFO: 經濟部公告：修正「許可業者自行檢定之法定度量衡器種類及範圍」，自即日生效.pdf\n",
      "2019-01-10 17:28:59,812 - <ipython-input-82-1f7a555caa04>[line:11] - INFO: ./Result/經濟部公告：修正「許可業者自行檢定之法定度量衡器種類及範圍」/經濟部公告：修正「許可業者自行檢定之法定度量衡器種類及範圍」，自即日生效.pdf\n",
      "2019-01-10 17:29:00,919 - <ipython-input-84-04431583ed67>[line:7] - INFO: 制定文化內容策進院設置條例\n",
      "2019-01-10 17:29:01,083 - <ipython-input-84-04431583ed67>[line:7] - INFO: 修正替代役實施條例條文\n",
      "2019-01-10 17:29:01,271 - <ipython-input-84-04431583ed67>[line:7] - INFO: 新北市政府108年1月9日新北府法規字第1072515111號令：修正「新北市房屋稅徵收率自治條例」第二條。\n",
      "2019-01-10 17:29:01,376 - <ipython-input-84-04431583ed67>[line:17] - ERROR: 爬取內文失敗\n",
      "\n",
      "2019-01-10 17:29:01,377 - <ipython-input-84-04431583ed67>[line:18] - ERROR: 失敗連結：http://web.law.ntpc.gov.tw/fn/ShowNews.asp?id=5261\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\urllib3\\contrib\\pyopenssl.py\", line 444, in wrap_socket\n",
      "    cnx.do_handshake()\n",
      "  File \"C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\OpenSSL\\SSL.py\", line 1907, in do_handshake\n",
      "    self._raise_ssl_error(self._ssl, result)\n",
      "  File \"C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\OpenSSL\\SSL.py\", line 1639, in _raise_ssl_error\n",
      "    _raise_current_error()\n",
      "  File \"C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\OpenSSL\\_util.py\", line 54, in exception_from_error_queue\n",
      "    raise exception_type(errors)\n",
      "OpenSSL.SSL.Error: [('SSL routines', 'ssl3_get_server_certificate', 'certificate verify failed')]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\", line 600, in urlopen\n",
      "    chunked=chunked)\n",
      "  File \"C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\", line 343, in _make_request\n",
      "    self._validate_conn(conn)\n",
      "  File \"C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\", line 849, in _validate_conn\n",
      "    conn.connect()\n",
      "  File \"C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\urllib3\\connection.py\", line 356, in connect\n",
      "    ssl_context=context)\n",
      "  File \"C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\urllib3\\util\\ssl_.py\", line 359, in ssl_wrap_socket\n",
      "    return context.wrap_socket(sock, server_hostname=server_hostname)\n",
      "  File \"C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\urllib3\\contrib\\pyopenssl.py\", line 450, in wrap_socket\n",
      "    raise ssl.SSLError('bad handshake: %r' % e)\n",
      "ssl.SSLError: (\"bad handshake: Error([('SSL routines', 'ssl3_get_server_certificate', 'certificate verify failed')])\",)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\requests\\adapters.py\", line 445, in send\n",
      "    timeout=timeout\n",
      "  File \"C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\", line 638, in urlopen\n",
      "    _stacktrace=sys.exc_info()[2])\n",
      "  File \"C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\urllib3\\util\\retry.py\", line 398, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='web.law.ntpc.gov.tw', port=443): Max retries exceeded with url: /fn/ShowNews.asp?id=5261 (Caused by SSLError(SSLError(\"bad handshake: Error([('SSL routines', 'ssl3_get_server_certificate', 'certificate verify failed')])\")))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-84-04431583ed67>\", line 8, in parsingDetail\n",
      "    soup = request2soup(link)\n",
      "  File \"<ipython-input-89-70ed9c0d2877>\", line 4, in request2soup\n",
      "    res = requests.get(url)\n",
      "  File \"C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\requests\\api.py\", line 72, in get\n",
      "    return request('get', url, params=params, **kwargs)\n",
      "  File \"C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\requests\\api.py\", line 58, in request\n",
      "    return session.request(method=method, url=url, **kwargs)\n",
      "  File \"C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\requests\\sessions.py\", line 512, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\requests\\sessions.py\", line 644, in send\n",
      "    history = [resp for resp in gen] if allow_redirects else []\n",
      "  File \"C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\requests\\sessions.py\", line 644, in <listcomp>\n",
      "    history = [resp for resp in gen] if allow_redirects else []\n",
      "  File \"C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\requests\\sessions.py\", line 222, in resolve_redirects\n",
      "    **adapter_kwargs\n",
      "  File \"C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\requests\\sessions.py\", line 622, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\requests\\adapters.py\", line 511, in send\n",
      "    raise SSLError(e, request=request)\n",
      "requests.exceptions.SSLError: HTTPSConnectionPool(host='web.law.ntpc.gov.tw', port=443): Max retries exceeded with url: /fn/ShowNews.asp?id=5261 (Caused by SSLError(SSLError(\"bad handshake: Error([('SSL routines', 'ssl3_get_server_certificate', 'certificate verify failed')])\")))\n",
      "2019-01-10 17:29:01,384 - <ipython-input-84-04431583ed67>[line:7] - INFO: 財政部令：核釋「貨物稅條例」第23條有關旅客自國外攜帶不隨身行李物品之貨物稅徵免相關規定\n",
      "2019-01-10 17:29:03,246 - <ipython-input-82-1f7a555caa04>[line:8] - INFO: 財政部令：核釋「貨物稅條例」第23條有關旅客自國外攜帶不隨身行李物品之貨物稅徵免相關規定.pdf\n",
      "2019-01-10 17:29:03,341 - <ipython-input-82-1f7a555caa04>[line:11] - INFO: ./Result/財政部令：核釋「貨物稅條例」第23條有關旅客自國外攜帶不隨身/財政部令：核釋「貨物稅條例」第23條有關旅客自國外攜帶不隨身行李物品之貨物稅徵免相關規定.pdf\n",
      "2019-01-10 17:29:04,101 - <ipython-input-84-04431583ed67>[line:7] - INFO: 海洋委員會公告：訂定「海洋保育類野生動物名錄」，自108年1月9日生效\n",
      "2019-01-10 17:29:06,035 - <ipython-input-82-1f7a555caa04>[line:8] - INFO: 海洋委員會公告：訂定「海洋保育類野生動物名錄」，自108年1月9日生效.pdf\n",
      "2019-01-10 17:29:06,132 - <ipython-input-82-1f7a555caa04>[line:11] - INFO: ./Result/海洋委員會公告：訂定「海洋保育類野生動物名錄」，自108年1/海洋委員會公告：訂定「海洋保育類野生動物名錄」，自108年1月9日生效.pdf\n",
      "2019-01-10 17:29:49,945 - <ipython-input-90-6ad1ddc58d47>[line:24] - CRITICAL: 結束時間：2019/01/10 17:29:49\n",
      "2019-01-10 17:29:49,948 - <ipython-input-90-6ad1ddc58d47>[line:25] - CRITICAL: 執行時間：94 秒\n",
      "2019-01-10 17:29:49,951 - <ipython-input-90-6ad1ddc58d47>[line:26] - CRITICAL: 輸出筆數：15 筆\n",
      "2019-01-10 17:29:49,956 - <ipython-input-90-6ad1ddc58d47>[line:27] - CRITICAL: 爬網結束......\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    url = 'https://www.moj.gov.tw/lp-22-001-1-20.html'\n",
    "    main(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "SSLError",
     "evalue": "HTTPSConnectionPool(host='web.law.ntpc.gov.tw', port=443): Max retries exceeded with url: /fn/ShowNews.asp?id=5261 (Caused by SSLError(SSLError(\"bad handshake: Error([('SSL routines', 'ssl3_get_server_certificate', 'certificate verify failed')])\")))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mError\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\contrib\\pyopenssl.py\u001b[0m in \u001b[0;36mwrap_socket\u001b[1;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname)\u001b[0m\n\u001b[0;32m    443\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 444\u001b[1;33m                 \u001b[0mcnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    445\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mOpenSSL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSSL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWantReadError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\OpenSSL\\SSL.py\u001b[0m in \u001b[0;36mdo_handshake\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1906\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSSL_do_handshake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ssl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1907\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_raise_ssl_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ssl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1908\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\OpenSSL\\SSL.py\u001b[0m in \u001b[0;36m_raise_ssl_error\u001b[1;34m(self, ssl, result)\u001b[0m\n\u001b[0;32m   1638\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1639\u001b[1;33m             \u001b[0m_raise_current_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\OpenSSL\\_util.py\u001b[0m in \u001b[0;36mexception_from_error_queue\u001b[1;34m(exception_type)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mError\u001b[0m: [('SSL routines', 'ssl3_get_server_certificate', 'certificate verify failed')]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mSSLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    599\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m                                                   chunked=chunked)\n\u001b[0m\u001b[0;32m    601\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    342\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 343\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    344\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m    848\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'sock'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 849\u001b[1;33m             \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    850\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    355\u001b[0m             \u001b[0mserver_hostname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhostname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 356\u001b[1;33m             ssl_context=context)\n\u001b[0m\u001b[0;32m    357\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\util\\ssl_.py\u001b[0m in \u001b[0;36mssl_wrap_socket\u001b[1;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir)\u001b[0m\n\u001b[0;32m    358\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mHAS_SNI\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mserver_hostname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 359\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrap_socket\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msock\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mserver_hostname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\contrib\\pyopenssl.py\u001b[0m in \u001b[0;36mwrap_socket\u001b[1;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname)\u001b[0m\n\u001b[0;32m    449\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mOpenSSL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSSL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 450\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mssl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSSLError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'bad handshake: %r'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    451\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSSLError\u001b[0m: (\"bad handshake: Error([('SSL routines', 'ssl3_get_server_certificate', 'certificate verify failed')])\",)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    444\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 445\u001b[1;33m                     \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    446\u001b[0m                 )\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    637\u001b[0m             retries = retries.increment(method, url, error=e, _pool=self,\n\u001b[1;32m--> 638\u001b[1;33m                                         _stacktrace=sys.exc_info()[2])\n\u001b[0m\u001b[0;32m    639\u001b[0m             \u001b[0mretries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\util\\retry.py\u001b[0m in \u001b[0;36mincrement\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    397\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 398\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    399\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='web.law.ntpc.gov.tw', port=443): Max retries exceeded with url: /fn/ShowNews.asp?id=5261 (Caused by SSLError(SSLError(\"bad handshake: Error([('SSL routines', 'ssl3_get_server_certificate', 'certificate verify failed')])\")))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mSSLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-79-08cec29a7939>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'http://web.law.ntpc.gov.tw/fn/ShowNews.asp?id=5261'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequest2soup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-76-6f1954a48442>\u001b[0m in \u001b[0;36mrequest2soup\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'http://web.law.ntpc.gov.tw'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpackages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murllib3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mssl_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDEFAULT_CIPHERS\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m':RC4-SHA'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'html.parser'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfrom_encoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'allow_redirects'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'get'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    510\u001b[0m         }\n\u001b[0;32m    511\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 512\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    513\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    514\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    642\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[1;31m# Resolve redirects if allowed.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 644\u001b[1;33m         \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mresp\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mresp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgen\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_redirects\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    645\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    646\u001b[0m         \u001b[1;31m# Shuffle things around if there's history.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    642\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[1;31m# Resolve redirects if allowed.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 644\u001b[1;33m         \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mresp\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mresp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgen\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_redirects\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    645\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    646\u001b[0m         \u001b[1;31m# Shuffle things around if there's history.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mresolve_redirects\u001b[1;34m(self, resp, req, stream, timeout, verify, cert, proxies, yield_requests, **adapter_kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m                     \u001b[0mproxies\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m                     \u001b[0mallow_redirects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m                     \u001b[1;33m**\u001b[0m\u001b[0madapter_kwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m                 )\n\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    620\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    621\u001b[0m         \u001b[1;31m# Send the request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 622\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    623\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m         \u001b[1;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    509\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreason\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_SSLError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m                 \u001b[1;31m# This branch is for urllib3 v1.22 and later.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mSSLError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    512\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSSLError\u001b[0m: HTTPSConnectionPool(host='web.law.ntpc.gov.tw', port=443): Max retries exceeded with url: /fn/ShowNews.asp?id=5261 (Caused by SSLError(SSLError(\"bad handshake: Error([('SSL routines', 'ssl3_get_server_certificate', 'certificate verify failed')])\")))"
     ]
    }
   ],
   "source": [
    "url = 'http://web.law.ntpc.gov.tw/fn/ShowNews.asp?id=5261'\n",
    "soup = request2soup(url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
